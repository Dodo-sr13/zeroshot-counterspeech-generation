{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from DataHandler.data import  *\n",
    "from DataHandler.mapping import  *\n",
    "from ModelCode.model import *\n",
    "from apiconfig import project_name,api_token\n",
    "import neptune.new as neptune\n",
    "import GPUtil\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from ModelCode.model import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel\n",
    "from transformers import AutoTokenizer, BertTokenizer, RobertaTokenizer\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel,RobertaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "  'dataset':'Dataset/jigsaw-toxic-severity-rating/validation_data.csv',\n",
    "  'model':'twitter-roberta-base-hate_reddit',\n",
    "  'cache_path':'Saved_Models/twitter-roberta-base-hate_reddit',\n",
    "#   'model_path':'bert-base-uncased_toxic_comment',\n",
    "  'max_length':256,\n",
    "  'dropout':0.2,\n",
    "  'random_seed':2021,\n",
    "  'device':'cuda',\n",
    "  'save_path':'Saved_Models/',\n",
    "  'logging':'local'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Found a gpu\n",
      "We will use the GPU: 1 Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "model_memory=1\n",
    "total_memory=16\n",
    "def get_gpu(gpu_id):\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    while(1):\n",
    "        tempID = [] \n",
    "        tempID = GPUtil.getAvailable(order = 'memory', limit = 2, maxLoad = 1.0, maxMemory = (1-(model_memory/total_memory)), includeNan=False, excludeID=[], excludeUUID=[])\n",
    "        for i in range(len(tempID)):\n",
    "            if len(tempID) > 0 and (tempID[i]==gpu_id):\n",
    "                print(\"Found a gpu\")\n",
    "                print('We will use the GPU:',tempID[i],torch.cuda.get_device_name(tempID[i]))\n",
    "                deviceID=[tempID[i]]\n",
    "                return deviceID\n",
    "            else:\n",
    "                time.sleep(5)\n",
    "                \n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "if torch.cuda.is_available() and params['device']=='cuda':    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    ##### You can set the device manually if you have only one gpu\n",
    "    ##### comment this line if you don't want to manually set the gpu\n",
    "    #deviceID = get_gpu(args.gpuid)\n",
    "    deviceID = get_gpu(1)\n",
    "    torch.cuda.set_device(deviceID[0])\n",
    "    #### comment this line if you want to manually set the gpu\n",
    "    #### required parameter is the gpu id\n",
    "    #torch.cuda.set_device(args.gpuid)\n",
    "\n",
    "else:\n",
    "    print('Since you dont want to use GPU, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelPred_lime():\n",
    "    def __init__(self):\n",
    "#         self.device = torch.device(\"cuda\")\n",
    "       \n",
    "        if('roberta' in params['cache_path']):\n",
    "            self.model = RobertaForRegression.from_pretrained(\n",
    "                    params['cache_path'],\n",
    "                    params={'dropout':0.2},local_files_only=True).to(device)\n",
    "            \n",
    "        elif('Hate-speech-CNERG/dehatebert-mono-english' in params['cache_path']):\n",
    "            self.model = HateAlert.from_pretrained(\n",
    "                    params['cache_path'],\n",
    "                    params={'dropout':0.2}).to(device)\n",
    "\n",
    "        else:\n",
    "            self.model = BertForRegression.from_pretrained(\n",
    "                    params['cache_path'],\n",
    "                    params={'dropout':0.2},  local_files_only=True).to(device)\n",
    "\n",
    "\n",
    "\n",
    "        if('roberta' in params['cache_path']):\n",
    "            self.tokenizer = RobertaTokenizer.from_pretrained(params['cache_path'])\n",
    "        \n",
    "        elif('dehatebert' in params['cache_path']):\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(params['cache_path'])\n",
    "        \n",
    "        else:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(params['cache_path'])\n",
    "\n",
    "        # print(\"Model Loaded!\")\n",
    "        # self.model.cuda()  \n",
    "        # self.model.eval()\n",
    "\n",
    "    # def preprocess_func(self, text):\n",
    "    #     remove_words=['<allcaps>','</allcaps>','<hashtag>','</hashtag>','<elongated>','<emphasis>','<repeated>','\\'','s']\n",
    "    #     word_list=text_processor.pre_process_doc(text)\n",
    "    #     word_list=list(filter(lambda a: a not in remove_words, word_list)) \n",
    "    #     sent=\" \".join(word_list)\n",
    "    #     sent = re.sub(r\"[<\\*>]\", \" \",sent)\n",
    "    #     return sent\n",
    "\n",
    "    def predict(self, model, dataloader):\n",
    "        predicted_label = []\n",
    "        actual_label = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for step,data in tqdm(enumerate(dataloader, 0), total=len(dataloader)):\n",
    "                input_ids = data['ids'].to(device, dtype = torch.long)\n",
    "                attention_mask = data['mask'].to(device, dtype = torch.long)\n",
    "                targets = data['targets'].to(device, dtype = torch.float32)\n",
    "                targets = targets.unsqueeze(1)\n",
    "\n",
    "    #             input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "                output = model(input_ids, attention_mask)\n",
    "                            \n",
    "                predicted_label += output[0]\n",
    "                actual_label += targets\n",
    "                \n",
    "        return predicted_label\n",
    "\n",
    "    def prediction(self, test_df):\n",
    "\n",
    "\n",
    "        test = pd.DataFrame()\n",
    "        test['text'] = test_df.copy()\n",
    "        test['label'] = 0\n",
    "#         print(test)\n",
    "\n",
    "        testing_set = Triage(test, self.tokenizer, params)\n",
    "\n",
    "        test_params = {'batch_size': 128,\n",
    "                       'shuffle': False,\n",
    "                        'num_workers': 0\n",
    "                        }\n",
    "\n",
    "        test_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "        output = self.predict(self.model, test_loader)\n",
    "\n",
    "        out2 =[]\n",
    "        for out in output:\n",
    "            out2.append(out.cpu().detach().numpy())\n",
    "\n",
    "        out = np.array(out2).reshape((len(out2),-1))\n",
    "#         out = np.hstack((out, 1-out))\n",
    "#         out = out.tolist()\n",
    "        \n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelClass=modelPred_lime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(params['dataset'])\n",
    "\n",
    "less = test_df['less_toxic'].copy()\n",
    "more = test_df['more_toxic'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [05:36<00:00,  1.43s/it]\n",
      "100%|██████████| 236/236 [05:46<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "test_df['less_score'] = modelClass.prediction(less)\n",
    "test_df['more_score'] = modelClass.prediction(more)\n",
    "test_df['diff'] = test_df['less_score'] - test_df['more_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.drop(columns = ['worker'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('Predicitions/' + params['model'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass = test_df[test_df['diff'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-cd547b7b836f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass.sort_values('diff', ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "misclass.sort_values('diff', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-04daaf1f665e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass.drop_duplicates(subset=['less_toxic', 'more_toxic'], keep='first', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "misclass.drop_duplicates(subset=['less_toxic', 'more_toxic'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass = misclass.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass.to_csv('Top200Misclassified/' + params['model'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
