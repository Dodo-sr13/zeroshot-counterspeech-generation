{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from DataHandler.data import  *\n",
    "from DataHandler.mapping import  *\n",
    "from ModelCode.model import *\n",
    "from apiconfig import project_name,api_token\n",
    "import neptune.new as neptune\n",
    "import GPUtil\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "from ModelCode.model import *\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel\n",
    "from transformers import AutoTokenizer, BertTokenizer, RobertaTokenizer\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel,RobertaModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "  'dataset':'toxic_unintended',\n",
    "  'model':'cardiffnlp/twitter-roberta-base-hate',\n",
    "  'features':'tfidf',\n",
    "  'cache_path':'../../Saved_models/',\n",
    "  'model_path':'cardiffnlp/twitter-roberta-base-hate',\n",
    "  'train_batch_size':16,\n",
    "  'val_batch_size':32,\n",
    "  'max_length':256,\n",
    "  'learning_rate':5e-5,  ### learning rate 2e-5 for bert 0.001 for gru\n",
    "  'weight_decay':1e-5,\n",
    "  'epsilon':1e-8,\n",
    "  'epochs':3,\n",
    "  'dropout':0.2,\n",
    "  'random_seed':2021,\n",
    "  'device':'cuda',\n",
    "  'save_path':'Saved_Models/',\n",
    "  'logging':'local'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelPred_lime():\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        \n",
    "        class_weights=torch.tensor([1.0,1.0,1.0]).to(self.device)\n",
    "   \n",
    "        if('roberta' in params['model_path']):\n",
    "            model = RobertaForRegression.from_pretrained(\n",
    "                    params['model_path'], # Use the 12-layer BERT model, with an uncased vocab.\n",
    "                    cache_dir=params['cache_path'],\n",
    "                    params=params).to(self.device)\n",
    "            \n",
    "        elif('Hate-speech-CNERG/dehatebert-mono-english' in params['model_path']):\n",
    "            model = HateAlert.from_pretrained(\n",
    "                    params['model_path'], \n",
    "                    cache_dir=params['cache_path'],\n",
    "                    params=params).to(self.device)\n",
    "\n",
    "        else:\n",
    "            model = BertForRegression.from_pretrained(\n",
    "                    params['model_path'], # Use the 12-layer BERT model, with an uncased vocab.\n",
    "                    cache_dir=params['cache_path'],\n",
    "                    params=params).to(self.device)\n",
    "\n",
    "\n",
    "        if('roberta' in params['model_path']):\n",
    "            tokenizer = RobertaTokenizer.from_pretrained(params['model_path'])\n",
    "        \n",
    "        elif('dehatebert' in params['model_path']):\n",
    "            tokenizer = AutoTokenizer.from_pretrained(params['model_path'])\n",
    "        \n",
    "        else:\n",
    "            tokenizer = BertTokenizer.from_pretrained(params['model_path'])\n",
    "\n",
    "        # print(\"Model Loaded!\")\n",
    "        # self.model.cuda()  \n",
    "        # self.model.eval()\n",
    "\n",
    "    # def preprocess_func(self, text):\n",
    "    #     remove_words=['<allcaps>','</allcaps>','<hashtag>','</hashtag>','<elongated>','<emphasis>','<repeated>','\\'','s']\n",
    "    #     word_list=text_processor.pre_process_doc(text)\n",
    "    #     word_list=list(filter(lambda a: a not in remove_words, word_list)) \n",
    "    #     sent=\" \".join(word_list)\n",
    "    #     sent = re.sub(r\"[<\\*>]\", \" \",sent)\n",
    "    #     return sent\n",
    "\n",
    "    def predict(self, model, dataloader, device):\n",
    "        predicted_label = []\n",
    "        actual_label = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for step,data in tqdm(enumerate(dataloader, 0), total=len(dataloader)):\n",
    "                input_ids = data['ids'].to(device, dtype = torch.long)\n",
    "                attention_mask = data['mask'].to(device, dtype = torch.long)\n",
    "                targets = data['targets'].to(device, dtype = torch.float32)\n",
    "                targets = targets.unsqueeze(1)\n",
    "\n",
    "    #             input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "                output = model(input_ids, attention_mask)\n",
    "                            \n",
    "                predicted_label += output[0]\n",
    "                actual_label += targets\n",
    "                \n",
    "        return predicted_label\n",
    "\n",
    "    def prediction(self, sentences):\n",
    "\n",
    "        test = pd.DataFrame()\n",
    "        test['text'] = sentences\n",
    "        test['labels'] = 0\n",
    "\n",
    "        testing_set = Triage(test, self.tokenizer, MAX_LEN = 256)\n",
    "\n",
    "        test_params = {'batch_size': 1,\n",
    "                       'shuffle': False,\n",
    "                        'num_workers': 0\n",
    "                        }\n",
    "\n",
    "        test_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "        output = self.predict(self.model, test_loader, self.device)\n",
    "\n",
    "        out2 =[]\n",
    "        for out in output:\n",
    "            out2.append(out.cpu().detach().numpy())\n",
    "\n",
    "        out = np.array(out2).reshape(len(out2))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "    # def tokenize(self, sentences, padding = True, max_len = 128):\n",
    "    #     input_ids, attention_masks, token_type_ids, rationales = [], [], [], []\n",
    "    #     # self.tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast = False)\n",
    "    #     self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "    #     for sent in sentences:\n",
    "    #         encoded_dict = self.tokenizer.encode_plus(sent,\n",
    "    #                                                 add_special_tokens=True,\n",
    "    #                                                 max_length=max_len, \n",
    "    #                                                 padding='max_length', \n",
    "    #                                                 return_attention_mask = True,\n",
    "    #                                                 return_tensors = 'pt', \n",
    "    #                                                 truncation = True)\n",
    "    #         input_ids.append(encoded_dict['input_ids'])\n",
    "    #         attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "    #     input_ids = torch.cat(input_ids, dim=0)\n",
    "    #     attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    #     return {'input_ids': input_ids, 'attention_masks': attention_masks}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelClass=modelPred_lime(params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelClass.prediction(['I am good'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = LimeTextExplainer(class_names=['normal','fearspeech','hatespeech'],split_expression='\\s+',random_state=333,bow=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
